{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doc_classification_doc2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Vyxa--1wCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Q5GR0y2Dzz",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4pll-dDPfDI",
        "colab_type": "text"
      },
      "source": [
        "We are converting the data i.e. the content of the xml files into a dictionary which will then be converted to a dataframe so that we could play with the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXV87guo16Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from binascii import hexlify\n",
        "\n",
        "\n",
        "path_a = '/content/drive/My Drive/xml_dataset/Class_A'\n",
        "path_b = '/content/drive/My Drive/xml_dataset/Class_B'\n",
        "\n",
        "dict = {'name': [],\n",
        "        'label': []}\n",
        "\n",
        "# Saving class A samples into the dictionary\n",
        "for filename in glob.glob(os.path.join(path_a, '*.xml')):\n",
        "    bin_data = open(filename, 'rb').read()\n",
        "    # new = hexlify(bin_data)\n",
        "    dict['name'].append(bin_data)\n",
        "    dict['label'].append(0) \n",
        "\n",
        "print(\"done importing class a\")\n",
        "\n",
        "\n",
        "# Saving class B samples into the dictionary\n",
        "for filename in glob.glob(os.path.join(path_b, '*.xml')):\n",
        "    bin_data = open(filename, 'rb').read()\n",
        "    # new = hexlify(bin_data)\n",
        "    dict['name'].append(bin_data)\n",
        "    dict['label'].append(1) \n",
        "\n",
        "print(\"done importing class b\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FVrNXEGPu6K",
        "colab_type": "text"
      },
      "source": [
        "Conversion of the newly created dictionary to a dataframe to be saved in a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGjG_PFV2AOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.DataFrame(dict) \n",
        "df.to_csv('/content/drive/My Drive/xml.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUHmShAt2GfC",
        "colab_type": "text"
      },
      "source": [
        "**Starting the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcV01wmwP2Gt",
        "colab_type": "text"
      },
      "source": [
        "Some necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NlsCmbCv-bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pGyEFt4QQkT",
        "colab_type": "text"
      },
      "source": [
        "Reading the csv file into a dataframe and checking if there exists any null values in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ikhMfPVwAaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/xml.csv')\n",
        "df = df[['name','label']]\n",
        "df = df[pd.notnull(df['name'])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4woa5PhbgqRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lisMdp5sWAE9",
        "colab_type": "text"
      },
      "source": [
        "Some visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z-fQ8hkV-gc",
        "colab_type": "code",
        "outputId": "3357a018-ec9d-4d1a-8647-f84d2855f458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "cnt_pro = df['label'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
        "plt.ylabel('Number', fontsize=12)\n",
        "plt.xlabel('Label', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEGCAYAAACuBLlKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAYRLkGAIBB/h+KwsRxvX+yKQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlkTrfG2Qh08",
        "colab_type": "text"
      },
      "source": [
        "Splitting the data into train and test sets (80/20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Tu2nr-wpJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmK8L72JQ8NX",
        "colab_type": "text"
      },
      "source": [
        "We are tokenizing the content with [nltk tokenizer](https://www.nltk.org/api/nltk.tokenize.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LwPq433wshk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNZToKqxwvV0",
        "colab_type": "code",
        "outputId": "ccba9061-a32f-4ab7-c693-a72bd5963c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY6LLliIRkVi",
        "colab_type": "text"
      },
      "source": [
        "Tagging every 'name' with its corresponding label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ejp3PXw25c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tagged = train.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['name']), tags=[r.label]), axis=1)\n",
        "test_tagged = test.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['name']), tags=[r.label]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5bl_SZNSBNd",
        "colab_type": "text"
      },
      "source": [
        "There are two algorithms in doc2vec; Distributed Bag of Words (DBOW) & Distributed Memory (DM). We try both of them separately and then concatenate both of them in the end "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBjmlcDpxFLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MbU6t8mSjDC",
        "colab_type": "text"
      },
      "source": [
        "***dm=0*** is used for DBOW, here the vectors are created by training a neural network which basically predicts the probability distribution of a portion of string taken from the document\n",
        "\n",
        "***min_count = 2*** drops strings with frequency of occurence lower than 2\n",
        "\n",
        "***workers = cores*** for parallel processing\n",
        "\n",
        "***sample = 0*** used for downsampling\n",
        "\n",
        "***vector_size = 300*** feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKVKwpAbxBm8",
        "colab_type": "code",
        "outputId": "59e03648-8f38-4daa-ed91-fbf44e59d116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432/432 [00:00<00:00, 535918.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jru5wHxqUW95",
        "colab_type": "text"
      },
      "source": [
        "Training for 30 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dApFJ5PxGvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arVqinQnUeXG",
        "colab_type": "text"
      },
      "source": [
        "Building the final vector for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRXMQIWSxb2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsrD9HQmxfaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbzz0BjAUo3T",
        "colab_type": "text"
      },
      "source": [
        "Training the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH_IAOpRxgsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn6XyZLfxpZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7LMD2x3Uu-h",
        "colab_type": "text"
      },
      "source": [
        "Now trying the second approach: DM. Rather than working on the occurences of strings, it remembers the context in which they are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gLCqlM_zybf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
        "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh5l2AXUz0w4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dmm.alpha -= 0.002\n",
        "    model_dmm.min_alpha = model_dmm.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flU3csYaz3Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRQUdOoTz5b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZstKb-F7VLRt",
        "colab_type": "text"
      },
      "source": [
        "Freeing up some RAM (might be skipped)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEUndVwZz5zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
        "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDHWyP0-z7MP",
        "colab_type": "code",
        "outputId": "49e334cc-7098-4276-d07a-ebbb5a8d0603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install testfixtures"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting testfixtures\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/fe/0cf62bbb32c3589e955a447d582c9d07b051baf5edc3fae9973709766353/testfixtures-6.10.2-py2.py3-none-any.whl (86kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: testfixtures\n",
            "Successfully installed testfixtures-6.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L85qaOuVTe3",
        "colab_type": "text"
      },
      "source": [
        "It is a know fact that combination of both DBOW and DM gives boost to the performance so we are concatenating both of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w04Ak20Dz90Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
        "\n",
        "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avwDFMkUz_Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vectors(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5mOQ0Pw0AqH",
        "colab_type": "code",
        "outputId": "9f8b10da-1cf5-4a09-cf6c-03941855e4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train, X_train = get_vectors(new_model, train_tagged)\n",
        "y_test, X_test = get_vectors(new_model, test_tagged)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Ql_uGF0CC2",
        "colab_type": "code",
        "outputId": "52076ad2-57fe-42ca-e6c3-2ca6239d7c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy 0.9537037037037037\n",
            "Testing F1 score: 0.95378740772628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i-cnhrU1B0M",
        "colab_type": "text"
      },
      "source": [
        "**Saving the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fafZ8KShxxj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(logreg, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W6yWCSl08M_",
        "colab_type": "text"
      },
      "source": [
        "**Testing the newly saved model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QviHMJDlzlG0",
        "colab_type": "code",
        "outputId": "c7682e35-897f-47c9-eb88-b9b2ef47fb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, y_test)\n",
        "\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9537037037037037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpzWGqWImA-Y",
        "colab_type": "text"
      },
      "source": [
        "Testing a single sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ-4--iUZo2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content = open('/content/drive/My Drive/other/204_b.xml', 'rb').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1bwpxAndUUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict = {'name': [],\n",
        "        'label': []}\n",
        "dict['name'].append(str(content))\n",
        "dict['label'].append(None)\n",
        "content_df = pd.DataFrame(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeK3JJ5CkqKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_df = pd.DataFrame(dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBIpXuc6eskv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mulc8_iQdVHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "content_tagged = content_df.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['name']), tags=[r.label]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wmSQ0n3dkLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, sample = vec_for_learning(new_model, content_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb-wjn3ChoRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = loaded_model.predict(sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su1GDsjJld4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}